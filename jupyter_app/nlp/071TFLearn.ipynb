{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로 추상화와 간소화, TFLearn\n",
    "\n",
    "> TFLearn은 텐서플로의 추상화 라이브러리이다. 이번에는 **TFLearn** 에 대해 알아보도록 하자.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFLearn 설치\n",
    "\n",
    "[TFLearn](http://tflearn.org/)은 텐서플로에 포함되어 있지 않기 때문에 별도의 설치가 필요하다. Terminal(또는 cmd창)에 pip 명령을 이용해 설치할 수 있다.\n",
    "\n",
    "```\n",
    "pip install tflearn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "TFLearn은 Chap07.1 - tf.estimator와 유사하지만, TFLearn을 사용하면 조금 더 깔끔하게 모델을 만들 수 있다. TFLearn.org에서는 TFLearn을 다음과 같이 소개하고 있다.\n",
    "\n",
    "> Easy-to-use and understand high-level API for implementing deep neural networks, with tutorial and examples.\n",
    "\n",
    "> Fast prototyping through highly modular built-in neural network layers, regularizers, optimizers, metrics...\n",
    "\n",
    "> Full transparency over Tensorflow. All functions are built over tensors and can be used independently of TFLearn.\n",
    "\n",
    "> Powerful helper functions to train any TensorFlow graph, with support of multiple inputs, outputs and optimizers.\n",
    "\n",
    "> Easy and beautiful graph visualization, with details about weights, gradients, activations and more...\n",
    "\n",
    "> Effortless device placement for using multiple CPU/GPU.\n",
    "\n",
    " \n",
    "\n",
    "TFLearn에서의 모델 생성은 ```regression()```을 사용하여 래핑되고 마무리된다. ```regression()```함수에서 손실함수(loss) 및 최적화(optimizer)를 설정해준다.\n",
    "\n",
    "그렇다면, TFLearn을 이용해 MNIST 데이터를 분류하는 CNN 모델을 만들어 보도록 하자.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tflearn\n",
    "import tflearn.datasets.mnist as mnist\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "# 데이터를 로딩하고 기본적인 변환을 수행\n",
    "train_x, train_y, test_x, test_y = mnist.load_data(one_hot=True, \n",
    "                                                   data_dir='../data')\n",
    "train_x = train_x.reshape([-1, 28, 28, 1])\n",
    "test_x = test_x.reshape([-1, 28, 28, 1])\n",
    "\n",
    "# Building the network\n",
    "CNN = input_data(shape=[None, 28, 28, 1], name='input')\n",
    "CNN = conv_2d(CNN, 32, 5, activation='relu', regularizer=\"L2\")\n",
    "CNN = max_pool_2d(CNN, 2)\n",
    "CNN = local_response_normalization(CNN)\n",
    "CNN = conv_2d(CNN, 64, 5, activation='relu', regularizer='L2')\n",
    "CNN = max_pool_2d(CNN, 2)\n",
    "CNN = local_response_normalization(CNN)\n",
    "CNN = fully_connected(CNN, 1024, activation=None)\n",
    "CNN = dropout(CNN, 0.5)\n",
    "CNN = fully_connected(CNN, 10, activation='softmax')\n",
    "CNN = regression(CNN, optimizer='adam', learning_rate=0.0001, \n",
    "                 loss='categorical_crossentropy', name='target')\n",
    "\n",
    "# Training the network\n",
    "model = tflearn.DNN(CNN, tensorboard_verbose=0, \n",
    "                    tensorboard_dir='./MNIST_tflearn_board/', \n",
    "                    checkpoint_path='./MNIST_tflearn_checkpoints/checkpoint')\n",
    "model.fit({'input': train_x}, {'target': train_y}, n_epoch=3,\n",
    "          validation_set=({'input': test_x}, {'target': test_y}),\n",
    "          snapshot_step=1000, show_metric=True, run_id='convnet_mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드에서 `tflearn.DNN()`함수는 `tf.estimator.Estimator()`와 비슷한 기능을 하는데, `regression()`으로 래핑된 모델을 인스턴스화하고 만들어진 모델을 전달하는 역할을 한다. 또한 텐서보드(TensorBoard)와 체크포인트(checkpoint) 디렉터리 등을 설정할 수 있다. 모델 적합 연산은 `.fit()` 메서드를 이용해 수행된다. \n",
    "\n",
    "모델 적합(`.fit()`), 즉 학습이 완료되면, 다음과 같은 메소드를 이용해 모델을 평가, 예측, 저장 및 불러오기 등을 수행할 수 있다.\n",
    "\n",
    "| 메서드\t| 설명|\n",
    "|:---|:---|\n",
    "| `evaluate(X, Y, batch_size)` | 주어진 샘플에서 모델을 평가|\n",
    "| `fit(X, Y, n_epoch)` | 입력 feature X와 타겟 Y를 모델에 적용하여 학습|\n",
    "| `get_weights(weight_tensor)` | 변수의 가중치를 반환|\n",
    "| `load(model_file)` | 학습된 모델 가중치를 불러오기|\n",
    "| `predict(x)` | 주어진 x 데이터를 모델을 이용해 예측|\n",
    "| `save(model_file)` | 학습된 모델 가중치를 저장|\n",
    "| `set_weights(tensor, weights)` | 주어진 값을 텐서 변수에 할당|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the network\n",
    "evaluation = model.evaluate(X=test_x, Y=test_y, batch_size=128)\n",
    "print(evaluation)\n",
    "\n",
    "# Predict\n",
    "pred = model.predict(test_x)\n",
    "accuarcy = (np.argmax(pred, 1)==np.argmax(test_y, 1)).mean()\n",
    "print(accuarcy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN\n",
    "\n",
    "이번에는 TFLearn을 이용해 RNN을 구현해 보도록하자. 구현할 RNN 모델은 영화 리뷰에 대한 감성분석으로, 리뷰에 대해 좋거나/나쁘거나 두 개의 클래스를 분류하는 모델이다. 데이터는 학습 및 테스트 데이터가 각각 25,000개로 이루어진 [IMDb](https://www.imdb.com/interfaces/) 리뷰 데이터를 사용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\helpers\\summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\helpers\\trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "from tflearn.datasets import imdb\n",
    "\n",
    "# IMDb 데이터셋 로드\n",
    "(train_x, train_y), (test_x, test_y), _ = imdb.load_data(path='../data/imdb.pkl', \n",
    "                                                         n_words=10000,\n",
    "                                                         valid_portion=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 불러온 IMDb 데이터는 각각 다른 시퀀스 길이를 가지고 있으므로 최대 시퀀스 길이를 100으로 하여 `tflearn.data_utils.pad_sequences()`를 사용해 제로 패딩으로 시퀀스의 길이를 맞춰준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sequence padding and Converting labels to binary vectors\n",
    "train_x = pad_sequences(train_x, maxlen=100, value=0.)\n",
    "test_x = pad_sequences(test_x, maxlen=100, value=0.)\n",
    "train_y = to_categorical(train_y, nb_classes=2)\n",
    "test_y = to_categorical(test_y, nb_classes=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런다음, `tflearn.embedding()`으로 벡터 공간으로의 임베딩을 수행한다. 아래의 코드에서 확인할 수 있듯이 각 단어는 128 크기인 벡터에 매핑된다. 이렇게 임베딩된 결과를 `LSTM layer`와 `fully_connected layer`를 추가해 모델을 구성해준다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\layers\\core.py:81: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\initializations.py:174: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\layers\\recurrent.py:69: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\layers\\recurrent.py:681: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\optimizers.py:238: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# Building a LSTM network\n",
    "# Embedding\n",
    "RNN = tflearn.input_data([None, 100])\n",
    "RNN = tflearn.embedding(RNN, input_dim=10000, output_dim=128)\n",
    "\n",
    "# LSTM Cell\n",
    "RNN = tflearn.lstm(RNN, 128, dropout=0.8)\n",
    "RNN = tflearn.fully_connected(RNN, 2, activation='softmax')\n",
    "RNN = tflearn.regression(RNN, optimizer='adam', \n",
    "                         learning_rate=0.001, loss='categorical_crossentropy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7039  | total loss: \u001b[1m\u001b[32m0.08769\u001b[0m\u001b[0m | time: 68.039s\n",
      "| Adam | epoch: 010 | loss: 0.08769 - acc: 0.9794 -- iter: 22496/22500\n",
      "Training Step: 7040  | total loss: \u001b[1m\u001b[32m0.08062\u001b[0m\u001b[0m | time: 70.148s\n",
      "| Adam | epoch: 010 | loss: 0.08062 - acc: 0.9815 | val_loss: 0.71259 - val_acc: 0.8024 -- iter: 22500/22500\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Training the network\n",
    "model = tflearn.DNN(RNN, tensorboard_verbose=0, \n",
    "                    tensorboard_dir='./IMDb-tflearn_board/')\n",
    "model.fit(train_x, train_y, \n",
    "          validation_set=(test_x, test_y), \n",
    "          show_metric=True, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate the network\n",
    "evaluation = model.evaluate(test_x, test_y, batch_size=128)\n",
    "print(evaluation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChatApp_env",
   "language": "python",
   "name": "chat_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
